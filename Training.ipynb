{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62770a69-22ff-4ad2-bce7-f4665f07a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in d:\\anaconda\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=2.6.1 in d:\\anaconda\\lib\\site-packages (from pymongo) (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (D:\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\Anaconda\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56f7e4b-2912-47be-a337-ffb228b620fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Fetching data from MongoDB...\n",
      "ðŸ”„ Creating 72-hour targets by shifting historical data...\n",
      "âœ… Data Preparation Complete. Features: 7, Targets: 72\n",
      "ðŸ“Š Training Multi-Output Models...\n",
      "\n",
      "--- Ridge_Regression ---\n",
      "R2 Score: 0.3618\n",
      "MAE: 15.25 (Avg error per hour predicted)\n",
      "RMSE: 19.90\n",
      "\n",
      "--- Random_Forest ---\n",
      "R2 Score: 0.8672\n",
      "MAE: 5.79 (Avg error per hour predicted)\n",
      "RMSE: 9.07\n",
      "\n",
      "--- Gradient_Boosting ---\n",
      "R2 Score: 0.7177\n",
      "MAE: 9.71 (Avg error per hour predicted)\n",
      "RMSE: 13.24\n",
      "\n",
      "--- Neural_Network_MLP ---\n",
      "R2 Score: 0.6516\n",
      "MAE: 11.03 (Avg error per hour predicted)\n",
      "RMSE: 14.70\n",
      "\n",
      "âœ… All 4 models and the scaler have been saved as .pkl files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import certifi\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 1. Connect to MongoDB\n",
    "MONGO_URI = \"mongodb+srv://ali321hasnain_db_user:etRWe1e6ASFlpwEO@cluster0.1eklm6h.mongodb.net/?appName=Cluster0\"\n",
    "ca = certifi.where()\n",
    "client = MongoClient(MONGO_URI, tlsCAFile=ca)\n",
    "db = client[\"AQIPredictionSystem\"]\n",
    "collection = db[\"karachi_features\"]\n",
    "\n",
    "# 2. Load Data\n",
    "print(\"ðŸ“¥ Fetching data from MongoDB...\")\n",
    "df = pd.DataFrame(list(collection.find({}, {'_id': 0})))\n",
    "\n",
    "# Ensure data is sorted by time before we \"shift\" it\n",
    "# Note: Replace 'timestamp' with the actual column name in your MongoDB\n",
    "if 'timestamp' in df.columns:\n",
    "    df = df.sort_values('timestamp')\n",
    "\n",
    "# --- DATA TRANSFORMATION: CREATING THE 72 TARGETS ---\n",
    "print(\"ðŸ”„ Creating 72-hour targets by shifting historical data...\")\n",
    "target_cols = []\n",
    "for i in range(1, 73):\n",
    "    col_name = f'aqi_{i}h'\n",
    "    # Shifting moves future AQI values into the current row for training\n",
    "    df[col_name] = df['aqi'].shift(-i)\n",
    "    target_cols.append(col_name)\n",
    "\n",
    "# Drop rows at the end where we don't have future values (the last 3 days)\n",
    "df = df.dropna()\n",
    "\n",
    "# Define Features (X) and Multi-Output Targets (y)\n",
    "# Drop the target columns and non-numeric columns from X\n",
    "cols_to_drop = target_cols + ['aqi']\n",
    "if 'timestamp' in df.columns:\n",
    "    cols_to_drop.append('timestamp')\n",
    "\n",
    "X = df.drop(columns=cols_to_drop)\n",
    "y = df[target_cols]\n",
    "\n",
    "print(f\"âœ… Data Preparation Complete. Features: {X.shape[1]}, Targets: {y.shape[1]}\")\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# 3. Split Data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Feature Scaling (Must save this to use later in prediction)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. Define the 4 Multi-Output Models\n",
    "# MultiOutputRegressor lets standard models predict a vector (all 72 hours)\n",
    "models = {\n",
    "    \"Ridge_Regression\": MultiOutputRegressor(Ridge(alpha=1.0)),\n",
    "    \"Random_Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient_Boosting\": MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "    \"Neural_Network_MLP\": MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# 6. Train, Evaluate, and Save\n",
    "print(\"ðŸ“Š Training Multi-Output Models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Training\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Validation\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate Metrics (Average across all 72 hours)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.2f} (Avg error per hour predicted)\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    # Save the trained model file\n",
    "    joblib.dump(model, f\"{name}_model.pkl\")\n",
    "\n",
    "# Save the scaler (Crucial for the dashboard script)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"\\nâœ… All 4 models and the scaler have been saved as .pkl files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b3986-773d-412c-af58-7abc1b22d644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8dd5fe-ee78-4335-bea7-0a665f337ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
